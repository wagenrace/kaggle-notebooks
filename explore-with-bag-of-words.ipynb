{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb788f9",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "Not all features have to be complex to be usefull. Here are a few easy one that give you an idea if a text is a fake. However, it will be inconclusive about a lot of data.\n",
    "\n",
    "- Repeating of words.\n",
    "    - Fakes have repeating words like `AssemblyCulture AssemblyCulture AssemblyCulture AssemblyCulture AssemblyCulture when writing this response` in training data 5 file 2\n",
    "- Emtpy strings\n",
    "  - Same files are just empty like training data 14 file 1\n",
    "- None Latin or Greek letters\n",
    "    - We expect Latin letter for English a bit of Greek as math or science symbols but not `moeil ÿ™ŸÜÿ≤ŸäŸÑ ◊ê◊ó◊®◊ô◊ù –∑—ç—Ä—ç–≥ plumber ‡§â‡§§‡•ç‡§§ Sof regarded‡∞ø‡∞§ vriendin Fran√ßaisowedhjweise` like in training data 61 file 2\n",
    "- üá®üá≥ China, ü¶ñ Dinosaurs, and üéµ Music\n",
    "    - For some reason dinosaurs and China is said a lot in fakes like `Dinosaur eggshells offer clues about what` in training data 2 file 2\n",
    "    - Or `China is an interesting topic!` in training data 6 file 2\n",
    "    - Music comes from the test data but has examples like `The Extreme Ultraviolet Music Center uses a unique five lens system` in test data 28 file 1\n",
    "\n",
    "Combining all of these into 1 function gives us a prediction about 20% of the data. The rest we just guess a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790657d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Import needed package\n",
    "import regex as re\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62ca47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>real_text</th>\n",
       "      <th>fake_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Scientists can learn about how galaxies form a...</td>\n",
       "      <td>Dinosaur eggshells offer clues about what dino...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Analyzing how fast stars rotate within a galax...</td>\n",
       "      <td>Dinosaur Rex was excited about his new toy set...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Since its launch in '99, the Very Large Telesc...</td>\n",
       "      <td>AssemblyCulture AssemblyCulture AssemblyCultur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Advanced telescopes like Hubble and ALMA are p...</td>\n",
       "      <td>China is an interesting topic! It's possible t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>To identify all articles published on both NAS...</td>\n",
       "      <td>collected data from NASA's Astrophysics Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The Stellar Initial Mass Function (IMF) is an ...</td>\n",
       "      <td>Dinosaur eggs are an important part dinosaur r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Since around the year of its inception in astr...</td>\n",
       "      <td>Since around the year of its inception in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  real_text_id                                          real_text  \\\n",
       "0   0             1  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1   1             2  The project aims to achieve an accuracy level ...   \n",
       "2   2             1  Scientists can learn about how galaxies form a...   \n",
       "3   3             2  The importance for understanding how stars evo...   \n",
       "4   4             2  Analyzing how fast stars rotate within a galax...   \n",
       "5   5             1  Since its launch in '99, the Very Large Telesc...   \n",
       "6   6             1  Advanced telescopes like Hubble and ALMA are p...   \n",
       "7   7             1  To identify all articles published on both NAS...   \n",
       "8   8             1  The Stellar Initial Mass Function (IMF) is an ...   \n",
       "9   9             2  Since around the year of its inception in astr...   \n",
       "\n",
       "                                           fake_text  \n",
       "0  The China relay network has released a signifi...  \n",
       "1  China\\nThe goal of this project involves achie...  \n",
       "2  Dinosaur eggshells offer clues about what dino...  \n",
       "3  China\\nThe study suggests that multiple star s...  \n",
       "4  Dinosaur Rex was excited about his new toy set...  \n",
       "5  AssemblyCulture AssemblyCulture AssemblyCultur...  \n",
       "6  China is an interesting topic! It's possible t...  \n",
       "7  collected data from NASA's Astrophysics Data S...  \n",
       "8  Dinosaur eggs are an important part dinosaur r...  \n",
       "9  Since around the year of its inception in the ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\n",
    "    r\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    ")\n",
    "\n",
    "for i, row in training_data.iterrows():\n",
    "    id = int(row.id)\n",
    "    real_text_id = row.real_text_id\n",
    "    fake_text_id = 1 if real_text_id == 2 else 2\n",
    "\n",
    "    # Get file paths to text\n",
    "    files_path = Path(\n",
    "        rf\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/article_{str(id).zfill(4)}\"\n",
    "    )\n",
    "    real_text_path = files_path / f\"file_{real_text_id}.txt\"\n",
    "    fake_text_path = files_path / f\"file_{fake_text_id}.txt\"\n",
    "\n",
    "    # Load texts\n",
    "    real_text = real_text_path.read_text()\n",
    "    fake_text = fake_text_path.read_text()\n",
    "    training_data.loc[i, \"real_text\"] = real_text\n",
    "    training_data.loc[i, \"fake_text\"] = fake_text\n",
    "\n",
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccaa10",
   "metadata": {},
   "source": [
    "## üá®üá≥ China, ü¶ñ Dinosaurs, and üéµ Music\n",
    "The 10 fake text we have above have 4 talking about China, and 3 about Dinosaurs. So counting China and Dinosaurs can already help use with 70% of the fake texts (extrapolating way to much)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c205d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>real_text</th>\n",
       "      <th>fake_text</th>\n",
       "      <th>real_china_count</th>\n",
       "      <th>real_dino_count</th>\n",
       "      <th>fake_china_count</th>\n",
       "      <th>fake_dino_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The VIRSA (Visible Infrared Survey Telescope A...</td>\n",
       "      <td>The China relay network has released a signifi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The project aims to achieve an accuracy level ...</td>\n",
       "      <td>China\\nThe goal of this project involves achie...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The importance for understanding how stars evo...</td>\n",
       "      <td>China\\nThe study suggests that multiple star s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Advanced telescopes like Hubble and ALMA are p...</td>\n",
       "      <td>China is an interesting topic! It's possible t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>To identify all articles published on both NAS...</td>\n",
       "      <td>collected data from NASA's Astrophysics Data S...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Using detailed images from KMOS and MUSE instr...</td>\n",
       "      <td>We used data from two instruments - KMOS and M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  real_text_id                                          real_text  \\\n",
       "0    0             1  The VIRSA (Visible Infrared Survey Telescope A...   \n",
       "1    1             2  The project aims to achieve an accuracy level ...   \n",
       "3    3             2  The importance for understanding how stars evo...   \n",
       "6    6             1  Advanced telescopes like Hubble and ALMA are p...   \n",
       "7    7             1  To identify all articles published on both NAS...   \n",
       "13  13             1  Using detailed images from KMOS and MUSE instr...   \n",
       "\n",
       "                                            fake_text  real_china_count  \\\n",
       "0   The China relay network has released a signifi...               0.0   \n",
       "1   China\\nThe goal of this project involves achie...               0.0   \n",
       "3   China\\nThe study suggests that multiple star s...               0.0   \n",
       "6   China is an interesting topic! It's possible t...               0.0   \n",
       "7   collected data from NASA's Astrophysics Data S...               0.0   \n",
       "13  We used data from two instruments - KMOS and M...               0.0   \n",
       "\n",
       "    real_dino_count  fake_china_count  fake_dino_count  \n",
       "0               0.0               2.0              0.0  \n",
       "1               0.0               3.0              0.0  \n",
       "3               0.0               4.0              0.0  \n",
       "6               0.0               2.0              0.0  \n",
       "7               0.0               3.0              0.0  \n",
       "13              0.0               2.0              0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_word(text: str, word: str) -> int:\n",
    "    return len(re.findall(word.lower(), text.lower()))\n",
    "\n",
    "\n",
    "def count_dino(text: str) -> int:\n",
    "    return len(re.findall(\"dinosaur\", text.lower()))\n",
    "\n",
    "\n",
    "def count_china(text: str) -> int:\n",
    "    return len(re.findall(\"china\", text.lower()))\n",
    "\n",
    "\n",
    "for i, row in training_data.iterrows():\n",
    "    # Count real\n",
    "    training_data.loc[i, \"real_china_count\"] = count_word(row.real_text, \"china\")\n",
    "    training_data.loc[i, \"real_dino_count\"] = count_word(row.real_text, \"dinosaur\")\n",
    "\n",
    "    # Count fake\n",
    "    training_data.loc[i, \"fake_china_count\"] = count_word(row.fake_text, \"china\")\n",
    "    training_data.loc[i, \"fake_dino_count\"] = count_word(row.fake_text, \"dinosaur\")\n",
    "\n",
    "training_data[training_data.fake_china_count > 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea946b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 real have more China, 6 fake have more china. The rest is equal\n",
      "0 real have more dino, 8 fake have more dino. The rest is equal\n"
     ]
    }
   ],
   "source": [
    "more_china_real = (\n",
    "    training_data.real_china_count > training_data.fake_china_count\n",
    ").sum()\n",
    "more_china_fake = (\n",
    "    training_data.real_china_count < training_data.fake_china_count\n",
    ").sum()\n",
    "print(\n",
    "    f\"{more_china_real} real have more China, {more_china_fake} fake have more china. The rest is equal\"\n",
    ")\n",
    "\n",
    "more_dino_real = (training_data.real_dino_count > training_data.fake_dino_count).sum()\n",
    "more_dino_fake = (training_data.real_dino_count < training_data.fake_dino_count).sum()\n",
    "print(\n",
    "    f\"{more_dino_real} real have more dino, {more_dino_fake} fake have more dino. The rest is equal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecfe08",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "There are words that are clearly more in fake. But this method is a bit inefficient. Even thought 14/96 can be detected this way. Let see if we can increase it a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841905a1",
   "metadata": {},
   "source": [
    "## Repeating words\n",
    "Some text have a lot of repeating words. Like number 5 starts with `AssemblyCulture AssemblyCulture AssemblyCulture AssemblyCulture AssemblyCulture when writing this response`. This can also be a good way to find fakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1 [' part as']\n",
      "90 2 [', 2.5']\n",
      "2 real have to much repeat, 25 fake have to much repeat. The rest does not\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>real_text</th>\n",
       "      <th>fake_text</th>\n",
       "      <th>real_china_count</th>\n",
       "      <th>real_dino_count</th>\n",
       "      <th>fake_china_count</th>\n",
       "      <th>fake_dino_count</th>\n",
       "      <th>real_repeat</th>\n",
       "      <th>fake_repeat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>The Stellar Initial Mass Function (IMF) is an ...</td>\n",
       "      <td>Dinosaur eggs are an important part dinosaur r...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>A key focus of modern cosmology is to understa...</td>\n",
       "      <td>A main focus of modern cosmology is to underst...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  real_text_id                                          real_text  \\\n",
       "8    8             1  The Stellar Initial Mass Function (IMF) is an ...   \n",
       "90  90             2  A key focus of modern cosmology is to understa...   \n",
       "\n",
       "                                            fake_text  real_china_count  \\\n",
       "8   Dinosaur eggs are an important part dinosaur r...               0.0   \n",
       "90  A main focus of modern cosmology is to underst...               0.0   \n",
       "\n",
       "    real_dino_count  fake_china_count  fake_dino_count real_repeat fake_repeat  \n",
       "8               0.0               0.0              4.0        True       False  \n",
       "90              0.0               0.0              0.0        True        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_text = training_data.loc[5].fake_text\n",
    "\n",
    "\n",
    "def repeats_word_three_times(text: str) -> Tuple[bool, list]:\n",
    "    repeating_phrases = re.findall(r\"([^\\w].{4,})\\1+\", text.lower())\n",
    "    if len(repeating_phrases) > 0:\n",
    "        return True, repeating_phrases\n",
    "    else:\n",
    "        return False, []\n",
    "\n",
    "\n",
    "for i, row in training_data.iterrows():\n",
    "    real_repeats, phrases = repeats_word_three_times(row.real_text)\n",
    "    training_data.loc[i, \"real_repeat\"] = real_repeats\n",
    "    if real_repeats:\n",
    "        print(row.id, row.real_text_id, phrases)\n",
    "    training_data.loc[i, \"fake_repeat\"] = repeats_word_three_times(row.fake_text)[0]\n",
    "\n",
    "real_repeat_3 = (training_data.real_repeat).sum()\n",
    "fake_repeat_3 = (training_data.fake_repeat).sum()\n",
    "print(\n",
    "    f\"{real_repeat_3} real have to much repeat, {fake_repeat_3} fake have to much repeat. The rest does not\"\n",
    ")\n",
    "\n",
    "# If you have 1 repeat it can be normal English but 2 gets weirds\n",
    "training_data[(training_data.real_repeat)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47add6d9",
   "metadata": {},
   "source": [
    "## None latin characters\n",
    "The fake of number 61 has a lot of alphabets mixed. Here is a part of it `moeil ÿ™ŸÜÿ≤ŸäŸÑ ◊ê◊ó◊®◊ô◊ù –∑—ç—Ä—ç–≥ plumber ‡§â‡§§‡•ç‡§§ Sof regarded‡∞ø‡∞§ vriendin Fran√ßaisowedhjweise`. So it might be useful to count them to figure out if it is weird case of not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c777d453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reals with more none latin: 0\n",
      "Fakes with more none latin: 19\n",
      "Number of reals with a none latin character: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_text</th>\n",
       "      <th>fake_text</th>\n",
       "      <th>real_none_latin_count</th>\n",
       "      <th>fake_none_latin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>The Nasmyth rotator will utilize the Nasmyth A...</td>\n",
       "      <td>The Nasmyth rotator will utilize the Nasmyth A...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>To begin achieving this goal, we used the ESO ...</td>\n",
       "      <td>To progress toward this goal, we used the ESO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Certain areas of astronomy sometimes see rapid...</td>\n",
       "      <td>Certain areas of astronomy often see rapid adv...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>We determine accurate values for the total lit...</td>\n",
       "      <td>We determine accurate values for the total lit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>FLAMES Study of Old Open Clusters: Insights in...</td>\n",
       "      <td>FLAMES Study of Old Open Clusters: Insights on...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            real_text  \\\n",
       "60  The Nasmyth rotator will utilize the Nasmyth A...   \n",
       "61  To begin achieving this goal, we used the ESO ...   \n",
       "62  Certain areas of astronomy sometimes see rapid...   \n",
       "63  We determine accurate values for the total lit...   \n",
       "66  FLAMES Study of Old Open Clusters: Insights in...   \n",
       "\n",
       "                                            fake_text  real_none_latin_count  \\\n",
       "60  The Nasmyth rotator will utilize the Nasmyth A...                    0.0   \n",
       "61   To progress toward this goal, we used the ESO...                    0.0   \n",
       "62  Certain areas of astronomy often see rapid adv...                    0.0   \n",
       "63  We determine accurate values for the total lit...                    0.0   \n",
       "66  FLAMES Study of Old Open Clusters: Insights on...                    0.0   \n",
       "\n",
       "    fake_none_latin_count  \n",
       "60                  335.0  \n",
       "61                  315.0  \n",
       "62                  271.0  \n",
       "63                  285.0  \n",
       "66                  308.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_none_latin_letters(text):\n",
    "    # Search for things that are NOT\n",
    "    # \\p{Latin} Latin letters\n",
    "    # \\s empty spaces\n",
    "    # \\p{S} Symbols\n",
    "    # \\p{P} Punitions\n",
    "    # \\p{N} Numbers\n",
    "    # \\p{Greek} greek letters (boy do scientists love themselves some greek letters)\n",
    "    # \\¬µ for some reason ¬µ is not part of \\p{Greek}? Weird\n",
    "    return len(re.findall(\"[^\\p{Latin}\\s\\p{S}\\p{P}\\p{N}\\p{Greek}\\¬µ]+\", text))\n",
    "\n",
    "\n",
    "for i, row in training_data.iterrows():\n",
    "    training_data.loc[i, \"real_none_latin_count\"] = count_none_latin_letters(\n",
    "        row.real_text\n",
    "    )\n",
    "    training_data.loc[i, \"fake_none_latin_count\"] = count_none_latin_letters(\n",
    "        row.fake_text\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Reals with more none latin: {(training_data.real_none_latin_count > training_data.fake_none_latin_count).sum()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Fakes with more none latin: {(training_data.fake_none_latin_count > training_data.real_none_latin_count).sum()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of reals with a none latin character: {len(training_data[training_data.fake_none_latin_count > 0])}\"\n",
    ")\n",
    "training_data[training_data.fake_none_latin_count > 0][\n",
    "    [\"real_text\", \"fake_text\", \"real_none_latin_count\", \"fake_none_latin_count\"]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3b4a4",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Detection the unexpected characters gives a very good insight into fakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a6601",
   "metadata": {},
   "source": [
    "## Empty strings\n",
    "Lastly some strings are empty. If they are empty they are always fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f8dd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real text that are empty 0\n",
      "fake text that are empty 2\n"
     ]
    }
   ],
   "source": [
    "print(\"real text that are empty\", (training_data.real_text == \"\").sum())\n",
    "print(\"fake text that are empty\", (training_data.fake_text == \"\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae1154",
   "metadata": {},
   "source": [
    "# Make submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0482102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_real(text1: str, text2: str) -> int:\n",
    "    # Empty strings are fake\n",
    "    if len(text1) == 0:\n",
    "        return 2\n",
    "    if len(text2) == 0:\n",
    "        return 1\n",
    "\n",
    "    # Did you use weird letters\n",
    "    # If both are the same we continue\n",
    "    count1 = count_none_latin_letters(text1)\n",
    "    count2 = count_none_latin_letters(text2)\n",
    "    if count1 > count2:\n",
    "        return 2\n",
    "    if count2 > count1:\n",
    "        return 1\n",
    "\n",
    "    # China\n",
    "    china_1 = count_word(text1, \"china\")\n",
    "    china_2 = count_word(text2, \"china\")\n",
    "    if china_1 > china_2 and china_1 > 2:\n",
    "        return 2\n",
    "    if china_2 > china_1 and china_2 > 2:\n",
    "        return 1\n",
    "\n",
    "    # Dino\n",
    "    dino_1 = count_word(text1, \"dinosaur\")\n",
    "    dino_2 = count_word(text2, \"dinosaur\")\n",
    "    if dino_1 > dino_2 and dino_1 > 2:\n",
    "        return 2\n",
    "    if dino_2 > dino_1 and dino_2 > 2:\n",
    "        return 1\n",
    "\n",
    "    # Music\n",
    "    music_1 = count_word(text1, \"music\")\n",
    "    music_2 = count_word(text2, \"music\")\n",
    "    if music_1 > music_2 and music_1 > 2:\n",
    "        return 2\n",
    "    if music_2 > music_1 and music_2 > 2:\n",
    "        return 1\n",
    "\n",
    "    # AddTagHelper\n",
    "    AddTagHelper_1 = count_word(text1, \"AddTagHelper\")\n",
    "    AddTagHelper_2 = count_word(text2, \"AddTagHelper\")\n",
    "    if AddTagHelper_1 > AddTagHelper_2:\n",
    "        return 2\n",
    "    if AddTagHelper_2 > AddTagHelper_1:\n",
    "        return 1\n",
    "\n",
    "    # Repeating words\n",
    "    # If you repeat a word more then 3 and it is the most repeated\n",
    "    repeats_1 = repeats_word_three_times(text1)\n",
    "    repeats_2 = repeats_word_three_times(text2)\n",
    "    if repeats_1[0] and not repeats_2[0]:\n",
    "        print(\"repeated word\", repeats_1[1])\n",
    "        return 2\n",
    "    if repeats_2[0] and not repeats_1[0]:\n",
    "        print(\"repeated word\", repeats_2[1])\n",
    "        return 1\n",
    "\n",
    "    # No clue? You get a zero\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e7bce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 32 | incorrect: 0 | unknown: 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "      <th>real_text</th>\n",
       "      <th>fake_text</th>\n",
       "      <th>real_china_count</th>\n",
       "      <th>real_dino_count</th>\n",
       "      <th>fake_china_count</th>\n",
       "      <th>fake_dino_count</th>\n",
       "      <th>real_repeat</th>\n",
       "      <th>fake_repeat</th>\n",
       "      <th>real_none_latin_count</th>\n",
       "      <th>fake_none_latin_count</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, real_text_id, real_text, fake_text, real_china_count, real_dino_count, fake_china_count, fake_dino_count, real_repeat, fake_repeat, real_none_latin_count, fake_none_latin_count, prediction]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test is on training data\n",
    "for i, row in training_data.iterrows():\n",
    "    training_data.loc[i, \"prediction\"] = get_the_real(row.real_text, row.fake_text)\n",
    "\n",
    "unknowns = (training_data[\"prediction\"] == 0).sum()\n",
    "corrects = (training_data[\"prediction\"] == 1).sum()\n",
    "incorrects = (training_data[\"prediction\"] == 2).sum()\n",
    "\n",
    "print(f\"correct: {corrects} | incorrect: {incorrects} | unknown: {unknowns}\")\n",
    "\n",
    "training_data[training_data[\"prediction\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9132d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeated word [' royal observatory edinburgh royal observatory edinburgh']\n",
      "repeated word ['{ } { } ']\n",
      "repeated word ['; treatment from different treatment mechanisms', ' treatment']\n",
      "repeated word [' searching,']\n",
      "repeated word [' pave', ' royal']\n",
      "repeated word [' nasa', ' earth', ' be it', ' knowledge base']\n",
      "repeated word [' thanks again']\n",
      "repeated word [' royal']\n",
      "repeated word [' treatmen', ' treatme', ' treatm', ' treatmen', ' treatme']\n",
      "repeated word [' fruits from']\n",
      "repeated word [' with']\n",
      "repeated word [\" magic youth's proposal\", ' eigenen']\n",
      "repeated word [' erforschung dieser art von sternen relevant fur die']\n",
      "repeated word [' assemblyculture assemblyculture']\n",
      "repeated word [' earth', ' earthly', ' as part as part']\n",
      "repeated word [' treatment center', ' treating', ' treatment']\n",
      "repeated word [' de treatment', ' treatments', ' treatment', ' treatment treatme', ' or all parts']\n",
      "repeated word [' thousands upon']\n",
      "repeated word [' treatment']\n",
      "repeated word [' royal', ' royal royal royal']\n",
      "repeated word [' royalty royalties', ' royaltiroyalety', ' royalty royalty', ' royality', ' royality']\n",
      "repeated word [' by early']\n",
      "repeated word [' treatment', ' treatment', ' treatment']\n",
      "repeated word [' over time periods ranging anywhere between decades up until present day research efforts continue today due largely because new technologies such as advanced imaging techniques provide fresh perspectives allowing us learn new things about how these structures form over time periods ranging anywhere between decades up until present day research efforts continue today due largely because new technologies such as advanced imaging techniques provide fresh perspectives allowing us learn new things about how these structures form', ' development pattern analysis tools operating around specific portions ofthis intricate structure exist underfruit']\n",
      "repeated word [' royal commission on victoria harbour', ' commission on victoria harbourroyal', ' royal commission']\n",
      "repeated word [' magic bullet system']\n",
      "repeated word [' for eye treatments', ' for treatment']\n",
      "repeated word [' treatment de la', \" treatment de l'treatment de la\", ' treatment']\n",
      "repeated word [' robotic']\n",
      "repeated word [' royal society for nothing else', ' royal society', ' royal society royal society', \" royal observatory's public royal observatory's public\", ' royal observatory royal observatory']\n",
      "repeated word ['‚Äìread']\n",
      "repeated word [' enough \"magic\" covering about one tenth or less than one percent if you\\'s looking from far away! to see what kind magic was there before it needs']\n",
      "repeated word [' orbit around earths']\n",
      "repeated word [' treatment treatment', ' treatmen', ' treatment']\n",
      "repeated word ['.....']\n",
      "repeated word [' treatments for more than just', ' can be used by many people because it can be used by many people because it']\n",
      "repeated word [' treatment treatment', ' treatmen', ' treatme', ' treatme', ' yellow yellow']\n",
      "repeated word [' emission']\n",
      "repeated word [' worth']\n",
      "repeated word [' stargazers']\n",
      "repeated word [' royal blue', ' royal', ' roally', ' royal', ' royal', ' royal', ' rroal']\n",
      "repeated word [' fruitfully gathered']\n",
      "repeated word [' teenage']\n",
      "repeated word [' royal', ' royal']\n",
      "repeated word [' de la treatment']\n",
      "repeated word [' three']\n",
      "repeated word [' magic youthfully active young stars who just started out their lives but also have many unique qualities due to being new born']\n",
      "repeated word [' complex processes related phenomena related']\n",
      "repeated word [' over']\n",
      "repeated word [' billions upon']\n",
      "repeated word [' royalties', ' royal permission', ' royalityroyalty', ' royal', ' royaltyroyalty', ' royalty', ' royal ty has already got all its tools ready']\n",
      "repeated word [' tunnu kannalla et tunne subjektti tulppa subjektti', ' tunnu kannalla et kenalsubjekti tunnu kannalla et kenalsubjekti']\n",
      "repeated word [\" our solar systems robots on mars rovers from earth's orbit towards exploring beyond\", ' exploration programs that will help us understand how best to send humans into deep sea ocean', ' robot']\n",
      "repeated word [' royal']\n",
      "repeated word [' einen']\n",
      "repeated word ['\\nmovies']\n",
      "repeated word [' (megacam), territorias', ' observation period , eso']\n",
      "repeated word [' effective care']\n",
      "repeated word [' treatments de', ' treatment treatment treatment treatment', ' treatmen', ' treatme', ' treatm', ' treatment']\n",
      "repeated word [' planets or']\n",
      "repeated word [' royal blue royal blue']\n",
      "repeated word [' impacts how much detail we see on their images to be used for analysis because it', ' touniformly distributed particles within our atmosphere (like dust). these disturbances disrupt astronaut training programs causing delays during training sessions leading up']\n",
      "repeated word [' robotic']\n",
      "repeated word [' royalty', ' royaltyroyalty', ' royaltiroyalty']\n",
      "repeated word [' treatmen']\n",
      "repeated word [' magiclan']\n",
      "repeated word [' figurehead']\n",
      "repeated word [' treatments for data from various']\n",
      "repeated word [' royal', ' royal']\n",
      "repeated word [' royal observatory green bank royal observatory green bank', ' observatory green bankroyal', ' royal observatories']\n",
      "repeated word [' light royal blue']\n",
      "Submissions without predictions: 72.4%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id real_text_id\n",
       "0      0            2\n",
       "0      1            2\n",
       "0      2            1\n",
       "0      3            1\n",
       "0      4            2\n",
       "..   ...          ...\n",
       "0   1063            2\n",
       "0   1064            1\n",
       "0   1065            1\n",
       "0   1066            2\n",
       "0   1067            2\n",
       "\n",
       "[1068 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=[\"id\", \"real_text_id\"])\n",
    "test_path_base = Path(r\"/kaggle/input/fake-or-real-the-impostor-hunt/data/test\")\n",
    "for test_path in test_path_base.glob(\"**/article_*\"):\n",
    "    text_1 = (test_path / \"file_1.txt\").read_text()\n",
    "    text_2 = (test_path / \"file_2.txt\").read_text()\n",
    "    article_id = int(re.findall(\"\\d+\", test_path.name)[0])\n",
    "    real_id = get_the_real(text_1, text_2)\n",
    "\n",
    "    submission = pd.concat(\n",
    "        [pd.DataFrame([{\"id\": article_id, \"real_text_id\": real_id}]), submission]\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Submissions without predictions: {(submission.real_text_id == 0).sum() / len(submission) * 100:.1f}%\"\n",
    ")\n",
    "\n",
    "# Replace unknown with 1\n",
    "submission.loc[submission.real_text_id == 0, \"real_text_id\"] = 2\n",
    "submission = submission.sort_values(by=\"id\")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
