{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53609228",
   "metadata": {
    "papermill": {
     "duration": 0.002518,
     "end_time": "2025-07-22T14:33:41.429843",
     "exception": false,
     "start_time": "2025-07-22T14:33:41.427325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9d319d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:33:41.435386Z",
     "iopub.status.busy": "2025-07-22T14:33:41.435076Z",
     "iopub.status.idle": "2025-07-22T14:34:07.200210Z",
     "shell.execute_reply": "2025-07-22T14:34:07.199159Z"
    },
    "papermill": {
     "duration": 25.769905,
     "end_time": "2025-07-22T14:34:07.202035",
     "exception": false,
     "start_time": "2025-07-22T14:33:41.432130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805f403b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:34:07.218106Z",
     "iopub.status.busy": "2025-07-22T14:34:07.217792Z",
     "iopub.status.idle": "2025-07-22T14:34:12.930061Z",
     "shell.execute_reply": "2025-07-22T14:34:12.929306Z"
    },
    "papermill": {
     "duration": 5.722038,
     "end_time": "2025-07-22T14:34:12.931698",
     "exception": false,
     "start_time": "2025-07-22T14:34:07.209660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# üì¶ Import needed package\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd86441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:34:12.947875Z",
     "iopub.status.busy": "2025-07-22T14:34:12.947358Z",
     "iopub.status.idle": "2025-07-22T14:34:14.006093Z",
     "shell.execute_reply": "2025-07-22T14:34:14.005267Z"
    },
    "papermill": {
     "duration": 1.068593,
     "end_time": "2025-07-22T14:34:14.007710",
     "exception": false,
     "start_time": "2025-07-22T14:34:12.939117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>The observations of the Pluto-Charon binary an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>The observations of the Pluto-Charon system an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id file_id                                               text  \\\n",
       "0         94       2  The new detector system was first tested on 30...   \n",
       "1         94       1  The new detector system was first tested on 30...   \n",
       "2         93       2  The observations of the Pluto-Charon binary an...   \n",
       "3         93       1  The observations of the Pluto-Charon system an...   \n",
       "4         92       2  FORS1 and FORS2 are early instruments of the V...   \n",
       "\n",
       "  is_real  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       0  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading training data\n",
    "training_data_labels = pd.read_csv(\n",
    "    r\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    ")\n",
    "training_data = pd.DataFrame(columns=[\"article_id\", \"file_id\", \"text\", \"is_real\"])\n",
    "for i, row in training_data_labels.iterrows():\n",
    "    article_id = int(row.id)\n",
    "    real_text_id = row.real_text_id\n",
    "    fake_text_id = 1 if real_text_id == 2 else 2\n",
    "\n",
    "    # Get file paths to text\n",
    "    files_path = Path(\n",
    "        rf\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/article_{str(article_id).zfill(4)}\"\n",
    "    )\n",
    "    real_text_path = files_path / f\"file_{real_text_id}.txt\"\n",
    "    fake_text_path = files_path / f\"file_{fake_text_id}.txt\"\n",
    "\n",
    "    # file 1\n",
    "    file_1_path = files_path / \"file_1.txt\"\n",
    "    file_1 = file_1_path.read_text()\n",
    "    is_real = 1 if real_text_id == 1 else 0\n",
    "\n",
    "    training_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [[article_id, 1, file_1, is_real]], columns=training_data.columns\n",
    "            ),\n",
    "            training_data,\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # file 2\n",
    "    file_2_path = files_path / \"file_2.txt\"\n",
    "    file_2 = file_2_path.read_text()\n",
    "    is_real = 1 if real_text_id == 2 else 0\n",
    "\n",
    "    training_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [[article_id, 2, file_2, is_real]], columns=training_data.columns\n",
    "            ),\n",
    "            training_data,\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "# Show the first few rows of the training data\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66e8b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:34:14.023008Z",
     "iopub.status.busy": "2025-07-22T14:34:14.022671Z",
     "iopub.status.idle": "2025-07-22T14:34:27.659141Z",
     "shell.execute_reply": "2025-07-22T14:34:27.658306Z"
    },
    "papermill": {
     "duration": 13.645895,
     "end_time": "2025-07-22T14:34:27.660746",
     "exception": false,
     "start_time": "2025-07-22T14:34:14.014851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_95349/1714171192.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  article_id = int(re.findall(\"\\d+\", test_path_article.name)[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>variegated functionalities provided by starga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>The XClass software package allows astronomers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>880</td>\n",
       "      <td>2</td>\n",
       "      <td>The formal partnership between ESO and Chile b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>The formal relationship between ESO and Chile ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491</td>\n",
       "      <td>2</td>\n",
       "      <td>India's burgeoning aerospace program is making...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id file_id                                               text\n",
       "0         38       2  variegated functionalities provided by starga ...\n",
       "1         38       1  The XClass software package allows astronomers...\n",
       "2        880       2  The formal partnership between ESO and Chile b...\n",
       "3        880       1  The formal relationship between ESO and Chile ...\n",
       "4        491       2  India's burgeoning aerospace program is making..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "test_path = Path(r\"/kaggle/input/fake-or-real-the-impostor-hunt/data/test\")\n",
    "test_data = pd.DataFrame(columns=[\"article_id\", \"file_id\", \"text\"])\n",
    "for test_path_article in test_path.glob(\"**/article_*\"):\n",
    "    article_id = int(re.findall(\"\\d+\", test_path_article.name)[0])\n",
    "\n",
    "    # File 1\n",
    "    file_1_path = test_path_article / \"file_1.txt\"\n",
    "    file_1 = file_1_path.read_text()\n",
    "    test_data = pd.concat(\n",
    "        [pd.DataFrame([[article_id, 1, file_1]], columns=test_data.columns), test_data],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # File 2\n",
    "    file_2_path = test_path_article / \"file_2.txt\"\n",
    "    file_2 = file_2_path.read_text()\n",
    "    test_data = pd.concat(\n",
    "        [pd.DataFrame([[article_id, 2, file_2]], columns=test_data.columns), test_data],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b625b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-22T14:34:27.676371Z",
     "iopub.status.busy": "2025-07-22T14:34:27.676055Z",
     "iopub.status.idle": "2025-07-22T14:35:20.200801Z",
     "shell.execute_reply": "2025-07-22T14:35:20.199993Z"
    },
    "papermill": {
     "duration": 52.542557,
     "end_time": "2025-07-22T14:35:20.210726",
     "exception": false,
     "start_time": "2025-07-22T14:34:27.668169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_real</th>\n",
       "      <th>avg_token_vector_0</th>\n",
       "      <th>avg_token_vector_1</th>\n",
       "      <th>avg_token_vector_2</th>\n",
       "      <th>avg_token_vector_3</th>\n",
       "      <th>avg_token_vector_4</th>\n",
       "      <th>avg_token_vector_5</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_token_vector_290</th>\n",
       "      <th>avg_token_vector_291</th>\n",
       "      <th>avg_token_vector_292</th>\n",
       "      <th>avg_token_vector_293</th>\n",
       "      <th>avg_token_vector_294</th>\n",
       "      <th>avg_token_vector_295</th>\n",
       "      <th>avg_token_vector_296</th>\n",
       "      <th>avg_token_vector_297</th>\n",
       "      <th>avg_token_vector_298</th>\n",
       "      <th>avg_token_vector_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.077769</td>\n",
       "      <td>0.252392</td>\n",
       "      <td>-0.014818</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.141581</td>\n",
       "      <td>0.045727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184035</td>\n",
       "      <td>0.122638</td>\n",
       "      <td>0.152933</td>\n",
       "      <td>0.055888</td>\n",
       "      <td>0.149450</td>\n",
       "      <td>-0.070476</td>\n",
       "      <td>-0.061196</td>\n",
       "      <td>0.024034</td>\n",
       "      <td>-0.012061</td>\n",
       "      <td>0.133580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>The new detector system was first tested on 30...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074893</td>\n",
       "      <td>0.262910</td>\n",
       "      <td>-0.030370</td>\n",
       "      <td>-0.002416</td>\n",
       "      <td>-0.104175</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171178</td>\n",
       "      <td>0.102983</td>\n",
       "      <td>0.131961</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>0.140925</td>\n",
       "      <td>-0.070780</td>\n",
       "      <td>-0.061558</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>-0.027038</td>\n",
       "      <td>0.107565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>The observations of the Pluto-Charon binary an...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022929</td>\n",
       "      <td>0.105878</td>\n",
       "      <td>-0.012680</td>\n",
       "      <td>0.036975</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.201155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040706</td>\n",
       "      <td>-0.020288</td>\n",
       "      <td>0.014817</td>\n",
       "      <td>0.115498</td>\n",
       "      <td>0.196464</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>0.040387</td>\n",
       "      <td>-0.037965</td>\n",
       "      <td>0.112413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>The observations of the Pluto-Charon system an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.140410</td>\n",
       "      <td>-0.007820</td>\n",
       "      <td>0.031820</td>\n",
       "      <td>-0.014877</td>\n",
       "      <td>0.143297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073805</td>\n",
       "      <td>-0.017368</td>\n",
       "      <td>0.045915</td>\n",
       "      <td>0.107447</td>\n",
       "      <td>0.164487</td>\n",
       "      <td>0.033983</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>-0.001357</td>\n",
       "      <td>0.065037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>FORS1 and FORS2 are early instruments of the V...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.139084</td>\n",
       "      <td>0.078683</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>-0.015956</td>\n",
       "      <td>-0.091714</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270561</td>\n",
       "      <td>0.105031</td>\n",
       "      <td>0.093740</td>\n",
       "      <td>0.094304</td>\n",
       "      <td>0.067767</td>\n",
       "      <td>-0.002802</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>-0.047142</td>\n",
       "      <td>-0.030050</td>\n",
       "      <td>0.081389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id file_id                                               text  \\\n",
       "0         94       2  The new detector system was first tested on 30...   \n",
       "1         94       1  The new detector system was first tested on 30...   \n",
       "2         93       2  The observations of the Pluto-Charon binary an...   \n",
       "3         93       1  The observations of the Pluto-Charon system an...   \n",
       "4         92       2  FORS1 and FORS2 are early instruments of the V...   \n",
       "\n",
       "  is_real  avg_token_vector_0  avg_token_vector_1  avg_token_vector_2  \\\n",
       "0       0           -0.077769            0.252392           -0.014818   \n",
       "1       1           -0.074893            0.262910           -0.030370   \n",
       "2       1            0.022929            0.105878           -0.012680   \n",
       "3       0            0.032472            0.140410           -0.007820   \n",
       "4       1           -0.139084            0.078683           -0.013101   \n",
       "\n",
       "   avg_token_vector_3  avg_token_vector_4  avg_token_vector_5  ...  \\\n",
       "0           -0.000713           -0.141581            0.045727  ...   \n",
       "1           -0.002416           -0.104175            0.058519  ...   \n",
       "2            0.036975            0.006194            0.201155  ...   \n",
       "3            0.031820           -0.014877            0.143297  ...   \n",
       "4           -0.015956           -0.091714            0.057531  ...   \n",
       "\n",
       "   avg_token_vector_290  avg_token_vector_291  avg_token_vector_292  \\\n",
       "0             -0.184035              0.122638              0.152933   \n",
       "1             -0.171178              0.102983              0.131961   \n",
       "2             -0.040706             -0.020288              0.014817   \n",
       "3             -0.073805             -0.017368              0.045915   \n",
       "4             -0.270561              0.105031              0.093740   \n",
       "\n",
       "   avg_token_vector_293  avg_token_vector_294  avg_token_vector_295  \\\n",
       "0              0.055888              0.149450             -0.070476   \n",
       "1              0.046443              0.140925             -0.070780   \n",
       "2              0.115498              0.196464              0.038277   \n",
       "3              0.107447              0.164487              0.033983   \n",
       "4              0.094304              0.067767             -0.002802   \n",
       "\n",
       "   avg_token_vector_296  avg_token_vector_297  avg_token_vector_298  \\\n",
       "0             -0.061196              0.024034             -0.012061   \n",
       "1             -0.061558              0.028634             -0.027038   \n",
       "2             -0.001662              0.040387             -0.037965   \n",
       "3             -0.002963              0.016147             -0.001357   \n",
       "4              0.062450             -0.047142             -0.030050   \n",
       "\n",
       "   avg_token_vector_299  \n",
       "0              0.133580  \n",
       "1              0.107565  \n",
       "2              0.112413  \n",
       "3              0.065037  \n",
       "4              0.081389  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_EN = spacy.load(\"en_core_web_lg\")\n",
    "LEN_VECTOR = 300\n",
    "\n",
    "\n",
    "def encode_text(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encode the text using spaCy's language model.\n",
    "    Returns a 300-dimensional vector.\n",
    "    \"\"\"\n",
    "    tokens = NLP_EN(text)\n",
    "    tot_vector = np.zeros((LEN_VECTOR), dtype=np.float32)\n",
    "    num_tokens = 0\n",
    "    for token in tokens:\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        if token.pos_ not in [\"ADJ\", \"ADV\", \"NOUN\", \"PROPN\"]:\n",
    "            continue\n",
    "        if not token.has_vector or token.vector_norm == 0.0:\n",
    "            continue\n",
    "        tot_vector += token.vector\n",
    "        num_tokens += 1\n",
    "\n",
    "    if num_tokens == 0:\n",
    "        return np.zeros((LEN_VECTOR), dtype=np.float32)\n",
    "    else:\n",
    "        return tot_vector / num_tokens\n",
    "\n",
    "\n",
    "token_vectors = [f\"avg_token_vector_{i}\" for i in range(LEN_VECTOR)]\n",
    "\n",
    "for i, row in training_data.iterrows():\n",
    "    avg_token_vector = encode_text(row.text)\n",
    "    training_data.loc[i, token_vectors] = avg_token_vector\n",
    "\n",
    "training_data.to_csv(\"training_with_tokens.csv\", index=False)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378741a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>avg_token_vector_0</th>\n",
       "      <th>avg_token_vector_1</th>\n",
       "      <th>avg_token_vector_2</th>\n",
       "      <th>avg_token_vector_3</th>\n",
       "      <th>avg_token_vector_4</th>\n",
       "      <th>avg_token_vector_5</th>\n",
       "      <th>avg_token_vector_6</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_token_vector_290</th>\n",
       "      <th>avg_token_vector_291</th>\n",
       "      <th>avg_token_vector_292</th>\n",
       "      <th>avg_token_vector_293</th>\n",
       "      <th>avg_token_vector_294</th>\n",
       "      <th>avg_token_vector_295</th>\n",
       "      <th>avg_token_vector_296</th>\n",
       "      <th>avg_token_vector_297</th>\n",
       "      <th>avg_token_vector_298</th>\n",
       "      <th>avg_token_vector_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>variegated functionalities provided by starga ...</td>\n",
       "      <td>-0.072686</td>\n",
       "      <td>0.077947</td>\n",
       "      <td>-0.095928</td>\n",
       "      <td>-0.006755</td>\n",
       "      <td>-0.166210</td>\n",
       "      <td>0.076054</td>\n",
       "      <td>-0.008783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162650</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.181699</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.119881</td>\n",
       "      <td>-0.132444</td>\n",
       "      <td>-0.088043</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>0.104871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>The XClass software package allows astronomers...</td>\n",
       "      <td>-0.131740</td>\n",
       "      <td>0.018881</td>\n",
       "      <td>-0.119064</td>\n",
       "      <td>-0.056425</td>\n",
       "      <td>-0.191263</td>\n",
       "      <td>0.206301</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.357625</td>\n",
       "      <td>0.102077</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.214108</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>-0.063704</td>\n",
       "      <td>-0.108328</td>\n",
       "      <td>-0.033336</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>0.122139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>880</td>\n",
       "      <td>2</td>\n",
       "      <td>The formal partnership between ESO and Chile b...</td>\n",
       "      <td>-0.064031</td>\n",
       "      <td>-0.080080</td>\n",
       "      <td>0.189729</td>\n",
       "      <td>-0.046376</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.025267</td>\n",
       "      <td>-0.099314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035031</td>\n",
       "      <td>0.121565</td>\n",
       "      <td>0.090863</td>\n",
       "      <td>0.093841</td>\n",
       "      <td>0.164084</td>\n",
       "      <td>-0.120570</td>\n",
       "      <td>0.052982</td>\n",
       "      <td>-0.099918</td>\n",
       "      <td>-0.011719</td>\n",
       "      <td>0.050613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>The formal relationship between ESO and Chile ...</td>\n",
       "      <td>-0.060878</td>\n",
       "      <td>-0.091044</td>\n",
       "      <td>0.191662</td>\n",
       "      <td>-0.040135</td>\n",
       "      <td>0.049720</td>\n",
       "      <td>0.042741</td>\n",
       "      <td>-0.114613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010813</td>\n",
       "      <td>0.123970</td>\n",
       "      <td>0.073517</td>\n",
       "      <td>0.082049</td>\n",
       "      <td>0.188433</td>\n",
       "      <td>-0.116970</td>\n",
       "      <td>0.048559</td>\n",
       "      <td>-0.086427</td>\n",
       "      <td>-0.022030</td>\n",
       "      <td>0.035631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491</td>\n",
       "      <td>2</td>\n",
       "      <td>India's burgeoning aerospace program is making...</td>\n",
       "      <td>-0.105118</td>\n",
       "      <td>0.173255</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>-0.020586</td>\n",
       "      <td>-0.067639</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>-0.065683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170255</td>\n",
       "      <td>0.178009</td>\n",
       "      <td>-0.018299</td>\n",
       "      <td>0.064377</td>\n",
       "      <td>0.070335</td>\n",
       "      <td>-0.095826</td>\n",
       "      <td>-0.018371</td>\n",
       "      <td>0.072857</td>\n",
       "      <td>-0.040606</td>\n",
       "      <td>0.103267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  article_id file_id                                               text  \\\n",
       "0         38       2  variegated functionalities provided by starga ...   \n",
       "1         38       1  The XClass software package allows astronomers...   \n",
       "2        880       2  The formal partnership between ESO and Chile b...   \n",
       "3        880       1  The formal relationship between ESO and Chile ...   \n",
       "4        491       2  India's burgeoning aerospace program is making...   \n",
       "\n",
       "   avg_token_vector_0  avg_token_vector_1  avg_token_vector_2  \\\n",
       "0           -0.072686            0.077947           -0.095928   \n",
       "1           -0.131740            0.018881           -0.119064   \n",
       "2           -0.064031           -0.080080            0.189729   \n",
       "3           -0.060878           -0.091044            0.191662   \n",
       "4           -0.105118            0.173255            0.018863   \n",
       "\n",
       "   avg_token_vector_3  avg_token_vector_4  avg_token_vector_5  \\\n",
       "0           -0.006755           -0.166210            0.076054   \n",
       "1           -0.056425           -0.191263            0.206301   \n",
       "2           -0.046376            0.036825            0.025267   \n",
       "3           -0.040135            0.049720            0.042741   \n",
       "4           -0.020586           -0.067639            0.004712   \n",
       "\n",
       "   avg_token_vector_6  ...  avg_token_vector_290  avg_token_vector_291  \\\n",
       "0           -0.008783  ...             -0.162650              0.136994   \n",
       "1           -0.012274  ...             -0.357625              0.102077   \n",
       "2           -0.099314  ...             -0.035031              0.121565   \n",
       "3           -0.114613  ...             -0.010813              0.123970   \n",
       "4           -0.065683  ...             -0.170255              0.178009   \n",
       "\n",
       "   avg_token_vector_292  avg_token_vector_293  avg_token_vector_294  \\\n",
       "0              0.181699              0.082742              0.119881   \n",
       "1              0.095500              0.214108              0.044338   \n",
       "2              0.090863              0.093841              0.164084   \n",
       "3              0.073517              0.082049              0.188433   \n",
       "4             -0.018299              0.064377              0.070335   \n",
       "\n",
       "   avg_token_vector_295  avg_token_vector_296  avg_token_vector_297  \\\n",
       "0             -0.132444             -0.088043              0.019951   \n",
       "1             -0.063704             -0.108328             -0.033336   \n",
       "2             -0.120570              0.052982             -0.099918   \n",
       "3             -0.116970              0.048559             -0.086427   \n",
       "4             -0.095826             -0.018371              0.072857   \n",
       "\n",
       "   avg_token_vector_298  avg_token_vector_299  \n",
       "0              0.087751              0.104871  \n",
       "1             -0.001915              0.122139  \n",
       "2             -0.011719              0.050613  \n",
       "3             -0.022030              0.035631  \n",
       "4             -0.040606              0.103267  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in test_data.iterrows():\n",
    "    avg_token_vector = encode_text(row.text)\n",
    "    test_data.loc[i, token_vectors] = avg_token_vector\n",
    "\n",
    "test_data.to_csv(\"test_with_tokens.csv\", index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1fafb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc training: 0.463 with 1 neighbors\n",
      "acc training: 0.595 with 3 neighbors\n",
      "acc training: 0.668 with 5 neighbors\n",
      "acc training: 0.674 with 7 neighbors\n",
      "acc training: 0.753 with 9 neighbors\n",
      "acc training: 0.732 with 11 neighbors\n",
      "acc training: 0.753 with 13 neighbors\n",
      "acc training: 0.737 with 15 neighbors\n",
      "acc training: 0.742 with 17 neighbors\n",
      "acc training: 0.747 with 19 neighbors\n",
      "acc training: 0.753 with 21 neighbors\n",
      "acc training: 0.758 with 23 neighbors\n",
      "acc training: 0.768 with 25 neighbors\n",
      "acc training: 0.768 with 27 neighbors\n",
      "acc training: 0.763 with 29 neighbors\n",
      "acc training: 0.758 with 31 neighbors\n",
      "acc training: 0.753 with 33 neighbors\n",
      "acc training: 0.758 with 35 neighbors\n",
      "acc training: 0.758 with 37 neighbors\n",
      "acc training: 0.768 with 39 neighbors\n",
      "acc training: 0.784 with 41 neighbors\n",
      "acc training: 0.784 with 43 neighbors\n",
      "acc training: 0.795 with 45 neighbors\n",
      "acc training: 0.795 with 47 neighbors\n",
      "acc training: 0.789 with 49 neighbors\n",
      "acc training: 0.774 with 51 neighbors\n",
      "acc training: 0.774 with 53 neighbors\n",
      "acc training: 0.774 with 55 neighbors\n",
      "acc training: 0.774 with 57 neighbors\n",
      "acc training: 0.768 with 59 neighbors\n",
      "acc training: 0.763 with 61 neighbors\n",
      "acc training: 0.784 with 63 neighbors\n",
      "acc training: 0.779 with 65 neighbors\n",
      "acc training: 0.768 with 67 neighbors\n",
      "acc training: 0.768 with 69 neighbors\n",
      "acc training: 0.768 with 71 neighbors\n",
      "acc training: 0.779 with 73 neighbors\n",
      "acc training: 0.774 with 75 neighbors\n",
      "acc training: 0.763 with 77 neighbors\n",
      "acc training: 0.758 with 79 neighbors\n",
      "acc training: 0.742 with 81 neighbors\n",
      "acc training: 0.737 with 83 neighbors\n",
      "acc training: 0.732 with 85 neighbors\n",
      "acc training: 0.721 with 87 neighbors\n",
      "acc training: 0.737 with 89 neighbors\n",
      "acc training: 0.732 with 91 neighbors\n",
      "acc training: 0.711 with 93 neighbors\n"
     ]
    }
   ],
   "source": [
    "# Nearest neighbor search\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "for num_neight in range(2, 96, 2):\n",
    "    # Fit the model\n",
    "    train_array = np.array(training_data[token_vectors])\n",
    "    nbrs = NearestNeighbors(n_neighbors=num_neight, algorithm=\"ball_tree\").fit(\n",
    "        train_array\n",
    "    )\n",
    "\n",
    "    # Find the nearest neighbors for each training data point\n",
    "    distances, indices = nbrs.kneighbors(train_array)\n",
    "\n",
    "    all_correct = 0\n",
    "    for indic in indices:\n",
    "        prediction = training_data.iloc[indic[1:]].is_real.mode()[0]\n",
    "        # First neighbor it always itself\n",
    "        true_y = training_data.iloc[indic[0]].is_real\n",
    "        all_correct += prediction == true_y\n",
    "\n",
    "    print(\n",
    "        f\"acc training: {all_correct/len(training_data):.3f} with {num_neight-1} neighbors\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4327442",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs_test = NearestNeighbors(n_neighbors=45, algorithm=\"ball_tree\").fit(train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bedde45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_text_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id real_text_id\n",
       "0  0            2\n",
       "0  1            2\n",
       "0  2            1\n",
       "0  3            1\n",
       "0  4            2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(columns=[\"id\", \"real_text_id\"])\n",
    "test_array = np.array(test_data[token_vectors])\n",
    "\n",
    "distances, indices = nbrs_test.kneighbors(test_array)\n",
    "for article_id in range(test_data.article_id.max()):\n",
    "    index_file_1 = test_data[\n",
    "        (test_data.article_id == article_id) & (test_data.file_id == 1)\n",
    "    ].index\n",
    "    index_file_2 = test_data[\n",
    "        (test_data.article_id == article_id) & (test_data.file_id == 2)\n",
    "    ].index\n",
    "\n",
    "    indic_1 = indices[index_file_1]\n",
    "    indic_2 = indices[index_file_2]\n",
    "\n",
    "    pred_1 = training_data.iloc[indic_1[0]].is_real.mean()\n",
    "    pred_2 = training_data.iloc[indic_2[0]].is_real.mean()\n",
    "\n",
    "    # Get the highest prediction\n",
    "    if pred_1 > pred_2:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 1}]), submission]\n",
    "        )\n",
    "        continue\n",
    "    elif pred_2 > pred_1:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 2}]), submission]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # If prediction are equal get the lowest distant\n",
    "    dist_1 = distances[index_file_1].mean()\n",
    "    dist_2 = distances[index_file_2].mean()\n",
    "    if dist_2 > dist_1:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 1}]), submission]\n",
    "        )\n",
    "        continue\n",
    "    else:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 2}]), submission]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "submission = submission.sort_values(by=\"id\")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12964783,
     "sourceId": 105874,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.953667,
   "end_time": "2025-07-22T14:35:21.640430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T14:33:36.686763",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
