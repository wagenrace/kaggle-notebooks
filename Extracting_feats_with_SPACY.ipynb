{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53609228",
   "metadata": {
    "papermill": {
     "duration": 0.002518,
     "end_time": "2025-07-22T14:33:41.429843",
     "exception": false,
     "start_time": "2025-07-22T14:33:41.427325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encode with SPACY + nearest neighbors\n",
    "\n",
    "Spacy has token encoder in the form of a word2vector. This is made for similarity between tokens.\n",
    "Beside this Spacy also has features to figure out what token are stop word or nouns.\n",
    "\n",
    "The plan:\n",
    "\n",
    "1. From every text take all (Proper) Nouns, adverbs, and Adjectives that are not stop words but can be turned into vectors.\n",
    "   1. I only pick these given they are the most unique for the subject of a message\n",
    "2. Turn them into vectors\n",
    "3. Take the average vector per text\n",
    "4. Use this average vector to find the nearest neighbor to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d319d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:43:58.895308Z",
     "iopub.status.busy": "2025-07-23T19:43:58.895052Z",
     "iopub.status.idle": "2025-07-23T19:44:28.318494Z",
     "shell.execute_reply": "2025-07-23T19:44:28.317067Z",
     "shell.execute_reply.started": "2025-07-23T19:43:58.895285Z"
    },
    "papermill": {
     "duration": 25.769905,
     "end_time": "2025-07-22T14:34:07.202035",
     "exception": false,
     "start_time": "2025-07-22T14:33:41.432130",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f403b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:44:28.321747Z",
     "iopub.status.busy": "2025-07-23T19:44:28.321386Z",
     "iopub.status.idle": "2025-07-23T19:44:33.188979Z",
     "shell.execute_reply": "2025-07-23T19:44:33.187963Z",
     "shell.execute_reply.started": "2025-07-23T19:44:28.321715Z"
    },
    "papermill": {
     "duration": 5.722038,
     "end_time": "2025-07-22T14:34:12.931698",
     "exception": false,
     "start_time": "2025-07-22T14:34:07.209660",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Import needed package\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd86441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:44:33.194105Z",
     "iopub.status.busy": "2025-07-23T19:44:33.193810Z",
     "iopub.status.idle": "2025-07-23T19:44:34.685096Z",
     "shell.execute_reply": "2025-07-23T19:44:34.684190Z",
     "shell.execute_reply.started": "2025-07-23T19:44:33.194067Z"
    },
    "papermill": {
     "duration": 1.068593,
     "end_time": "2025-07-22T14:34:14.007710",
     "exception": false,
     "start_time": "2025-07-22T14:34:12.939117",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading training data\n",
    "training_data_labels = pd.read_csv(\n",
    "    r\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv\"\n",
    ")\n",
    "training_data = pd.DataFrame(columns=[\"article_id\", \"file_id\", \"text\", \"is_real\"])\n",
    "for i, row in training_data_labels.iterrows():\n",
    "    article_id = int(row.id)\n",
    "    real_text_id = row.real_text_id\n",
    "    fake_text_id = 1 if real_text_id == 2 else 2\n",
    "\n",
    "    # Get file paths to text\n",
    "    files_path = Path(\n",
    "        rf\"/kaggle/input/fake-or-real-the-impostor-hunt/data/train/article_{str(article_id).zfill(4)}\"\n",
    "    )\n",
    "    real_text_path = files_path / f\"file_{real_text_id}.txt\"\n",
    "    fake_text_path = files_path / f\"file_{fake_text_id}.txt\"\n",
    "\n",
    "    # file 1\n",
    "    file_1_path = files_path / \"file_1.txt\"\n",
    "    file_1 = file_1_path.read_text()\n",
    "    is_real = 1 if real_text_id == 1 else 0\n",
    "\n",
    "    training_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [[article_id, 1, file_1, is_real]], columns=training_data.columns\n",
    "            ),\n",
    "            training_data,\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # file 2\n",
    "    file_2_path = files_path / \"file_2.txt\"\n",
    "    file_2 = file_2_path.read_text()\n",
    "    is_real = 1 if real_text_id == 2 else 0\n",
    "\n",
    "    training_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [[article_id, 2, file_2, is_real]], columns=training_data.columns\n",
    "            ),\n",
    "            training_data,\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "# Show the first few rows of the training data\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e8b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:44:34.686387Z",
     "iopub.status.busy": "2025-07-23T19:44:34.686090Z",
     "iopub.status.idle": "2025-07-23T19:44:56.514654Z",
     "shell.execute_reply": "2025-07-23T19:44:56.513626Z",
     "shell.execute_reply.started": "2025-07-23T19:44:34.686354Z"
    },
    "papermill": {
     "duration": 13.645895,
     "end_time": "2025-07-22T14:34:27.660746",
     "exception": false,
     "start_time": "2025-07-22T14:34:14.014851",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_path = Path(r\"/kaggle/input/fake-or-real-the-impostor-hunt/data/test\")\n",
    "test_data = pd.DataFrame(columns=[\"article_id\", \"file_id\", \"text\"])\n",
    "for test_path_article in test_path.glob(\"**/article_*\"):\n",
    "    article_id = int(re.findall(\"\\d+\", test_path_article.name)[0])\n",
    "\n",
    "    # File 1\n",
    "    file_1_path = test_path_article / \"file_1.txt\"\n",
    "    file_1 = file_1_path.read_text()\n",
    "    test_data = pd.concat(\n",
    "        [pd.DataFrame([[article_id, 1, file_1]], columns=test_data.columns), test_data],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # File 2\n",
    "    file_2_path = test_path_article / \"file_2.txt\"\n",
    "    file_2 = file_2_path.read_text()\n",
    "    test_data = pd.concat(\n",
    "        [pd.DataFrame([[article_id, 2, file_2]], columns=test_data.columns), test_data],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b625b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:44:56.516018Z",
     "iopub.status.busy": "2025-07-23T19:44:56.515683Z",
     "iopub.status.idle": "2025-07-23T19:45:53.817551Z",
     "shell.execute_reply": "2025-07-23T19:45:53.816490Z",
     "shell.execute_reply.started": "2025-07-23T19:44:56.515991Z"
    },
    "papermill": {
     "duration": 52.542557,
     "end_time": "2025-07-22T14:35:20.210726",
     "exception": false,
     "start_time": "2025-07-22T14:34:27.668169",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NLP_EN = spacy.load(\"en_core_web_lg\")\n",
    "LEN_VECTOR = 300\n",
    "\n",
    "\n",
    "def encode_text(text: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Encode the text using spaCy's language model.\n",
    "    Returns a 300-dimensional vector.\n",
    "    \"\"\"\n",
    "    tokens = NLP_EN(text)\n",
    "    tot_vector = np.zeros((LEN_VECTOR), dtype=np.float32)\n",
    "    num_tokens = 0\n",
    "    for token in tokens:\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        if token.pos_ not in [\"ADJ\", \"ADV\", \"NOUN\", \"PROPN\"]:\n",
    "            continue\n",
    "        if not token.has_vector or token.vector_norm == 0.0:\n",
    "            continue\n",
    "        tot_vector += token.vector\n",
    "        num_tokens += 1\n",
    "\n",
    "    if num_tokens == 0:\n",
    "        return np.zeros((LEN_VECTOR), dtype=np.float32)\n",
    "    else:\n",
    "        return tot_vector / num_tokens\n",
    "\n",
    "\n",
    "token_vectors = [f\"avg_token_vector_{i}\" for i in range(LEN_VECTOR)]\n",
    "\n",
    "for i, row in training_data.iterrows():\n",
    "    avg_token_vector = encode_text(row.text)\n",
    "    training_data.loc[i, token_vectors] = avg_token_vector\n",
    "\n",
    "training_data.to_csv(\"training_with_tokens.csv\", index=False)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378741a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:45:53.820551Z",
     "iopub.status.busy": "2025-07-23T19:45:53.820255Z",
     "iopub.status.idle": "2025-07-23T19:55:38.435750Z",
     "shell.execute_reply": "2025-07-23T19:55:38.434647Z",
     "shell.execute_reply.started": "2025-07-23T19:45:53.820525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, row in test_data.iterrows():\n",
    "    avg_token_vector = encode_text(row.text)\n",
    "    test_data.loc[i, token_vectors] = avg_token_vector\n",
    "\n",
    "test_data.to_csv(\"test_with_tokens.csv\", index=False)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0240511",
   "metadata": {},
   "source": [
    "## Nearest Neighbors\n",
    "\n",
    "We use the testing data to find out how many neighbors is best, turns out 45 is the sweet spot. Yet I am here sitting in my attic not wishing to interact with 45 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fafb13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:55:38.437213Z",
     "iopub.status.busy": "2025-07-23T19:55:38.436828Z",
     "iopub.status.idle": "2025-07-23T19:56:15.384733Z",
     "shell.execute_reply": "2025-07-23T19:56:15.383466Z",
     "shell.execute_reply.started": "2025-07-23T19:55:38.437176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Nearest neighbor search\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "for num_neight in range(2, 96, 2):\n",
    "    # Fit the model\n",
    "    train_array = np.array(training_data[token_vectors])\n",
    "    nbrs = NearestNeighbors(n_neighbors=num_neight, algorithm=\"ball_tree\").fit(\n",
    "        train_array\n",
    "    )\n",
    "\n",
    "    # Find the nearest neighbors for each training data point\n",
    "    distances, indices = nbrs.kneighbors(train_array)\n",
    "\n",
    "    all_correct = 0\n",
    "    for indic in indices:\n",
    "        prediction = training_data.iloc[indic[1:]].is_real.mode()[0]\n",
    "        # First neighbor it always itself\n",
    "        true_y = training_data.iloc[indic[0]].is_real\n",
    "        all_correct += prediction == true_y\n",
    "\n",
    "    print(\n",
    "        f\"acc training: {all_correct/len(training_data):.3f} with {num_neight-1} neighbors\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4327442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:56:15.386195Z",
     "iopub.status.busy": "2025-07-23T19:56:15.385493Z",
     "iopub.status.idle": "2025-07-23T19:56:15.395059Z",
     "shell.execute_reply": "2025-07-23T19:56:15.394095Z",
     "shell.execute_reply.started": "2025-07-23T19:56:15.386060Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nbrs_test = NearestNeighbors(n_neighbors=45, algorithm=\"ball_tree\").fit(train_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f76d0ec",
   "metadata": {},
   "source": [
    "# make submission\n",
    "\n",
    "Each text will have it own prediction. We pick the file of which most neighbors are real. If both have the same number we pick the one with the lowest distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedde45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T19:56:15.396377Z",
     "iopub.status.busy": "2025-07-23T19:56:15.395972Z",
     "iopub.status.idle": "2025-07-23T19:56:32.576494Z",
     "shell.execute_reply": "2025-07-23T19:56:32.575420Z",
     "shell.execute_reply.started": "2025-07-23T19:56:15.396349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=[\"id\", \"real_text_id\"])\n",
    "test_array = np.array(test_data[token_vectors])\n",
    "\n",
    "distances, indices = nbrs_test.kneighbors(test_array)\n",
    "for article_id in range(test_data.article_id.max() + 1):\n",
    "    index_file_1 = test_data[\n",
    "        (test_data.article_id == article_id) & (test_data.file_id == 1)\n",
    "    ].index\n",
    "    index_file_2 = test_data[\n",
    "        (test_data.article_id == article_id) & (test_data.file_id == 2)\n",
    "    ].index\n",
    "\n",
    "    indic_1 = indices[index_file_1]\n",
    "    indic_2 = indices[index_file_2]\n",
    "\n",
    "    pred_1 = training_data.iloc[indic_1[0]].is_real.mean()\n",
    "    pred_2 = training_data.iloc[indic_2[0]].is_real.mean()\n",
    "\n",
    "    # Get the highest prediction\n",
    "    if pred_1 > pred_2:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 1}]), submission]\n",
    "        )\n",
    "        continue\n",
    "    elif pred_2 > pred_1:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 2}]), submission]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # If prediction are equal get the lowest distant\n",
    "    dist_1 = distances[index_file_1].mean()\n",
    "    dist_2 = distances[index_file_2].mean()\n",
    "    if dist_2 > dist_1:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 1}]), submission]\n",
    "        )\n",
    "        continue\n",
    "    else:\n",
    "        submission = pd.concat(\n",
    "            [pd.DataFrame([{\"id\": article_id, \"real_text_id\": 2}]), submission]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "submission = submission.sort_values(by=\"id\")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12964783,
     "sourceId": 105874,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.953667,
   "end_time": "2025-07-22T14:35:21.640430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-22T14:33:36.686763",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
